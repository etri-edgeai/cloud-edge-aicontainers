{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "721bce87-de49-450f-b788-d5df0772dd0f",
   "metadata": {},
   "source": [
    "# Redisai with resnet50\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fd7c45-b4c2-4fa0-92c2-809435ca7530",
   "metadata": {},
   "source": [
    "- https://oss.redis.com/redisai/commands/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d05c0f-8d89-4d19-8d19-14f62ced7ce9",
   "metadata": {},
   "source": [
    "### Arguments\n",
    "\n",
    "- __key__ : the model's key name\n",
    "\n",
    "\n",
    "- __backend__ : the backend for the model can be one of:\n",
    "\n",
    "  - TF : a TensorFlow backend\n",
    "  - TFLITE : The TensorFlow Lite backend\n",
    "  - TORCH : a PyTorch backend\n",
    "  - ONNX : a ONNX backend\n",
    "\n",
    "\n",
    "- __device__ : the device that will execute the model can be of:\n",
    "\n",
    "  - CPU : a CPU device\n",
    "  - GPU : a GPU device\n",
    "  - GPU:0 , ..., GPU:n : a specific GPU device on a multi-GPU system\n",
    "\n",
    "\n",
    "- __TAG__ : an optional string for tagging the model such as a version number or any arbitrary identifier\n",
    "\n",
    "\n",
    "- __BATCHSIZE__ : when provided with an n that is greater than 0, the engine will batch incoming requests from multiple clients that use the model with input tensors of the same shape. When AI.MODELEXECUTE (or AI.MODELRUN ) is called the requests queue is visited and input tensors from compatible requests are concatenated along the 0th (batch) dimension until n is exceeded. The model is then run for the entire batch and the results are unpacked back to the individual requests unblocking their respective clients. If the batch size of the inputs to of first request in the queue exceeds BATCHSIZE , the request is served immediately (default value: 0).\n",
    "\n",
    "\n",
    "- __MINBATCHSIZE__ : when provided with an m that is greater than 0, the engine will postpone calls to AI.MODELEXECUTE until the batch's size had reached m . In this case, note that requests for which m is not reached will hang indefinitely (default value: 0), unless MINBATCHTIMEOUT is provided.\n",
    "\n",
    "\n",
    "- __MINBATCHTIMEOUT__ : when provided with a t (expressed in milliseconds) that is greater than 0, the engine will trigger a run even though MINBATCHSIZE has not been reached after t milliseconds from the time a MODELEXECUTE (or the enclosing DAGEXECUTE ) is enqueued. This only applies to cases where both BATCHSIZE and MINBATCHSIZE are greater than 0.\n",
    "\n",
    "\n",
    "- __INPUTS__ : denotes that one or more names of the model's input nodes are following, applicable only for TensorFlow models (specifying INPUTS for other backends will cause an error)\n",
    "\n",
    "\n",
    "- __input_count__ : a positive number that indicates the number of following input nodes (also applicable only for TensorFlow)\n",
    "\n",
    "\n",
    "- __OUTPUTS__ : denotes that one or more names of the model's output nodes are following, applicable only for TensorFlow models (specifying OUTPUTS for other backends will cause an error)\n",
    "\n",
    "\n",
    "- __output_count__ : a positive number that indicates the number of following input nodes (also applicable only for TensorFlow)\n",
    "\n",
    "\n",
    "- __model__ : the Protobuf-serialized model. Since Redis supports strings up to 512MB, blobs for very large models need to be chunked, e.g. BLOB chunk1 chunk2 ... .\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec4abcce-e887-4d06-8134-ddef002253cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "! cat ./tmp/resnet50.pb | redis-cli -x AI.MODELSTORE resnet50 TF CPU TAG imagenet:5.0 INPUTS 1 images OUTPUTS 1 output BLOB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa174328-d499-4df1-b9d4-a8102ab77d6e",
   "metadata": {},
   "source": [
    "## 오류 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04aa7331-429f-4430-a5a7-6202e21c3677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(error) ERR INPUTS argument should not be specified for this backend\n"
     ]
    }
   ],
   "source": [
    "! cat ./tmp/iris.pt | redis-cli -x AI.MODELSTORE iris TORCH CPU TAG iris_csv_dataset INPUTS 3 vectors OUTPUTS 1 output BLOB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03128ab7-132e-450b-978c-6a720fd73785",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl4cv",
   "language": "python",
   "name": "dl4cv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
